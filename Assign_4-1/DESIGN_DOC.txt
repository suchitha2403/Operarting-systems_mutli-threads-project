The Data Structures used in this Assignment are 

User defined data type struct for storing the actions information

typedef struct{
	int user_id;			//for storing the id of node which generated that action
	int action_id;			//for storing the action number
	string action_type;		//for storing the type of the action
	time_t timestap;		//for storing the time at which that action is generated (in nanaoseconds)
} Action;

User defined data type struct for storing the complete Node information

typedef struct{
	int node_id;			//for storing Node id of that Node
	vector<int> adj;		//for storing the id values of all the nodes that are connected to this Node
	int degree;			//for storing degree of the Node
	queue<Action> Wallqueue;	//Wall queue for storing all the actions generated by this Node
	int couterlike;			//for storing no of likes generated by this node
	int counterpost; 		//for storing no of posts generated by this node
	int countercomment;		//for storing no of comments generated by this node
	
	priority_queue<pair<int, Action>, vector<pair<int, Action>>, Comparator> Feedqueue;	//Feed queue for storing all the actions of the Nodes which are adjacent to this Node
	//Above priority queue is used so that the actions when read by the node will be read on this basis of priority which is defined in comparator based on iven question
	
	int choice;			//for storing whether this node should read on priority basis (No of common neighbous) or chronological order
	
	pthread_mutex_t FeedMutex;	//Mutex lock for above feedqueue it is required because multiple pushupdate threads may access same feed queue 
	pthread_cond_t cond_feed;	//Conditional variable to send signals to all readpost threads which are waiting for element in feed queue
} Node;

struct Comparator     // comparator for the priority feed queue 
{   
    bool operator()(pair<int, Action> const &p1, pair<int, Action> const &p2)
    {
        return p1.first <= p2.first;
    }
};

queue<Action> shared_queue     //this shared queue is used to store the actions generated by all nodes so that push update threads access these and send them to corresponding feed queues
pthread_mutex_t shared_mutex     //this is used to lock the shared queue
pthread_cond_t cond_shared    //conditional variable to broadcast that shared_queue has been updated 
queue<int> shared_queue_2    //Every time when the action is pushed into any feed queue the node_id of that feed queue is pushed into shared_queue_2 so that readpost can take that node_id and get the most priority element from that particular feed queue
pthread_mutex_t shared_mutex_2     //this is used to lock the shared queue_2
pthread_cond_t cond_shared_2    //conditional variable to broadcast that shared_queue_2 has been updated

vector<vector<int>> dp(num_nodes, vector<int>(num_nodes, -1)) -> This matrix keeps track of the common neighbours count between every pair of nodes which is used for priority.(not precomputed)

Sizes of data structures used-

In the no particular size of queue is fixed because we are using STL queues and doing push_back and pop when queues need to be updated.
But in general in the worst case queue sizes can be as follows:

Size of wall queue - 10*(1+log2(37699))*(no if times the node is selected randolmy in usersimulator thread) -> if node is connected to all the other nodes
Size of shared queue - 100*Wall_queue_size_of_single_node_selected_randomly, if no pushupdate is done before generating all the actions of all the nodes
Size of feed queue - if(all the 100 nodes generated randomly are connected to this node and this node is not selected) ->  100*Wall_queue_size_of_single_node_selected_randomly
Size of shared queue 2 -> Feed queue size* no of nodes


Races and lock conditions-
1 -> lock on shared queue in usersimulator thread
    We need to lock the shared mutex to ensure mutual exclusion when multiple threads are accessing the shared queue. If multiple threads try to access the queue simultaneously, it can lead to race conditions, where the order and integrity of the data may be compromised.The lock ensures that only one thread has access to the shared queue at a time, and other threads are blocked until the lock is released by the current thread. This way, we can avoid race conditions and ensure the correctness of the program.

2-> lock on shared queue in pushupdate thread
   The pthread_mutex_lock function is used to acquire the lock before accessing the shared queue. This is important to ensure that no other thread is accessing or modifying the shared queue at the same time. Without the lock, there could be a race condition where two or more threads try to access or modify the shared queue simultaneously, which could lead to incorrect behavior or even program crashes.Similarly, the lock is also required before calling the pthread_cond_wait function. The pthread_cond_wait function is used to wait for a condition variable to be signaled by another thread. Before calling pthread_cond_wait, the lock must be acquired to ensure that no other thread modifies the shared data while the waiting thread is blocked. Once the condition variable is signaled and the waiting thread resumes execution, it reacquires the lock before accessing the shared data to prevent any race conditions.

3-> lock on feed queue in pushupdate thread
    The purpose of the pthread_mutex_lock call here is to ensure that only one thread is accessing/modifying the Feedqueue of the Node at a time. This is important to prevent data races and ensure thread safety.If multiple threads were allowed to modify the Feedqueue simultaneously without proper synchronization, it could result in unpredictable behavior such as race conditions, data corruption, or deadlock. Therefore, the pthread_mutex_lock call ensures that only one thread can hold the lock on the Feedmutex at a time, and any other threads attempting to access it will be blocked until the lock is released.

4-> lock on shared queue 2 in pushupdate thread
    We need to lock the mutex before modifying the shared_queue_2 in order to prevent race conditions, where multiple threads could be accessing the queue simultaneously and cause unexpected behavior. The lock ensures that only one thread can access the queue at a time and avoid any conflicts.

5 -> lock on shared queue 2 in readpost thread
   the shared_queue is a shared data structure, and it is being accessed by multiple threads concurrently. Therefore, a lock is needed to ensure that only one thread at a time can push an action into the queue, broadcast the condition variable, and unlock the mutex, ensuring the consistency of the queue.

6-> lock on feed queue in readpost thread
   the mutex lock is used to prevent multiple readpost threads from accessing the feed queue of the same node simultaneously. This is important because if multiple threads access the same queue at the same time, there is a possibility of them reading the same element, which can cause data inconsistency. Therefore, before accessing the feed queue, each readpost thread acquires the mutex lock to ensure exclusive access to the shared resource.

How concurrency is preserved in our design?
  Concurrency and parallelism in the code is preserved through the use of locks in critical sections of the code. Locks ensure that only one thread can access a shared resource (e.g. a queue or a variable) at a time.In the pushUpdate function, for example, the pthread_mutex_lock function is used to lock the feed queue of a particular node, ensuring that only one thread at a time can push an action into that queue. This prevents multiple threads from attempting to modify the same queue simultaneously, which could result in race conditions and unpredictable behavior.Similarly, in the readPost function, locks are used to ensure that only one thread at a time can access the shared feed queue and shared queue. This guarantees that each action is read and processed in the order it was generated, and prevents different threads from attempting to access the same queue at the same time.The use of locks in the code ensures that the threads execute atomically with respect to the shared resources, guaranteeing the correctness of the program's behavior. Without locks, concurrent threads could access and modify the same resource simultaneously, leading to race conditions, data inconsistencies, and unpredictable behavior.
     
